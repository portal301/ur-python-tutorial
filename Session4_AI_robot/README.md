# Session4: YOLO와 UR로봇 연동하기(Pick and Place 실습)

6일차 실습에서는 지금까지 배운 로봇 제어, 비전 인식, 데이터 처리 기법을 종합하여 **Pick and Place** 과제를 수행합니다. 
로봇이 평면 위의 물체를 감지하고, 원하는 물체를 집어서(Pick) 지정한 목표 지점에 놓는(Place) 과정을 구현합니다.

## 실습 목표
- **물체 인식**: 커스텀 YOLO 모델을 활용해 로봇이 대상 물체를 정확히 감지
- **위치 계산**: 3D 카메라와 로봇 좌표계를 이용해 물체 위치 추정
- **그리퍼 제어**: 감지한 물체를 안전하게 집고 놓는 동작 수행
- **통합 동작**: 인식–이동–파지–배치 과정을 하나의 시퀀스로 구현

## 진행 순서
1. **YOLO 학습을 위한 데이터셋 수집**  
   - 로봇과 카메라를 이용해 다양한 각도에서 대상 물체 촬영 및 데이터 수집
2. **데이터셋 전처리**  
   - 라벨링 툴을 사용하여 객체 경계 박스 및 OBB(Oriented Bounding Box) 라벨 생성  
   - 이미지 크기 조정, 색 보정 등 학습에 필요한 전처리
3. **YOLO Detection 및 OBB 모델 학습**  
   - 커스텀 데이터셋을 기반으로 YOLO 및 OBB 모델 학습  
   - 물체 방향까지 인식할 수 있도록 모델 최적화
4. **Pick and Place 실습**  
   - 학습한 모델로 실시간 객체 감지  
   - 감지 좌표를 로봇 제어 좌표로 변환  
   - 그리퍼를 이용해 물체 파지 후 목표 위치로 이동하여 배치

## 기대 효과
- 비전 기반 로봇 제어의 전 과정을 경험
- 인공지능 물체 인식과 로봇 동작의 통합 구현 능력 향상
- 산업 현장에서 빈번히 활용되는 Pick and Place 기술 이해
